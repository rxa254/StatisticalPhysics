\section{Boltzmann Factor: April 14}


\subsection{The Boltzmann Factor}
An important problem in Statistical Physics, is to find the probability
of finding a system in a state $s$ of energy $\epsilon_s$. We already
know how to do this for closed systems, but most systems are, in reality, open systems -- that is, they are in contact with a large thermal bath or reservoir. This might be the rest of the room (in the case of a tiny experiment) or the rest of the city (in the case that the system is a building) or even the rest of the universe (in astrophysical or cosmological cases). \\

So lets take our little system $\mathcal{S}$ and put in contact with our large reservoir $\mathcal{R}$ with initial energy $U_0$ and temperature $\tau_R$. Now we put our system in thermal (and later, mechanical) contact with the reservoir such that the new energy of the reservoir is $U_0 - \epsilon_s$. Now 
$\mathcal{R}$ can be in any of its $g_R(U_0 - \epsilon_s)$ microstates, just as we saw in last week's \textit{microcanonical} picture. \\

For a given state $s$, there is no degeneracy; the multiplicity, $g_s = 1$. So the probability of finding the total system ($\mathcal{S} + \mathcal{R}$) in the state where $\mathcal{S}$ has energy $\epsilon_s$, is just dependent on the multiplicity $g_R$: $P(s) \propto g_R(U_0 - \epsilon_s)$. Since 
$U_0 \gg \epsilon_s$, we can use the Taylor expansion to find a simplified form:

\begin{equation}
\log g_R = \sigma_R(U_0 - \epsilon_s) \simeq 
	\sigma_R(U_0) - 
	\epsilon_s \bigg(\frac{\partial \sigma_R}{\partial U_R}\bigg) +
	\mathcal{O}(\epsilon_s^2)
\end{equation}

Since $(\partial \sigma_R/\partial U_R) = 1/\tau_R$, we can rewrite the proportionality for the probability as:

\begin{equation}
P(s) \propto exp(-\epsilon_s/\tau_R)
\end{equation}

This is \textbf{one the most practically useful results in statistical physics}: it allows us to compute the relative probability of the system being in different energy states. This expression, $exp(-\epsilon_s/\tau_R)$, is called the
\emph{Boltzmann Factor}.


\subsection{Partition Function}
We would like to normalize the probability so that 
$\sum_s P(s) = 1$. To do this, we just sum over all possible energy states.

\begin{equation}
P(s) = \frac{exp(-\epsilon_s/\tau_R)}{\sum_s exp(-\epsilon_s/\tau_R)}
\label{eq:PofS}
\end{equation}
and where we will define the \emph{Partition Function}\footnote{an oddly named function for sure} as
\begin{equation}
Z(\tau_R) \equiv \sum_s exp(-\epsilon_s/\tau_R)
\end{equation}

There are many thermodynamic quantities which are easier to calculate using the partition function then going directly from the entropy or multiplicity alone. As an example, lets take a look at the average energy~\footnote{the last step is easier
to verify going backwards than forwards -- check it by doing the derivative}:

\begin{align}
U = \Braket{\epsilon_s} &= 
\frac{\sum_s \epsilon_s exp(-\epsilon_s/\tau_R)}{Z(\tau_R)} \\
	&= \tau_R^2 \bigg(\frac{\partial \log Z}{\partial \tau}\bigg) 
\end{align}

which is a sensible way to go as long as the partition function itself is easier to compute than $g(\epsilon_s)$. In fact, this is true for a large number of cases.

\subsection{Pressure}
What is pressure? From our own experience we know that its simply related to the force exerted on the walls of a container by the system that it contains. Consider a system (like a gas) inside of a box where one of the walls is able to move (i.e. a piston). What happens if we slowly extert a force on that piston? We know that the gas will be compressed. What will be the energy delivered to the box? 
Recall (cf.~\ref{s:FirstLaw}) the discussion on the First Law of 
Thermodynamics: $\Delta U = Q + W$. In the case that we do not allow heat to flow through the walls of the box, the change in energy will just be the work done on the system.
\begin{align}
dW &= F dx \\
   &= p (A dx) = p dV
\end{align}
here we have used the fact that pressure is defined as a force per unit area.
So we have that the change in energy, for a small change in volume is just
$dU = p dV$. If we make this change small enough and slowly enough, the change will be isentropic. The entropy is unchanged precisely the change in volume is made such that the microstate does not change (although the energy does).
Therefore we can define the pressure as:

\begin{equation}
p = -\bigg(\frac{\partial U}{\partial V}\bigg)_{\sigma}
\label{eq:Pressure}
\end{equation}

Why the minus sign? If we allow a balloon filled with gas to do work by expanding, we know that it is doing work and delivering energy to the environment. Therefore a positive change in volume of the system will \textit{decrease} the system's energy. So there's a minus sign.

$\sigma, U, V$, and $N$ are all \textit{extensive parameters} and $\sigma$ depends on the other three. If we leave $N$ fixed, there must be a clean relation between
$U$ and $V$ for all isentropic changes. The expression for the differential of
entropy will be:
\begin{equation}
d\sigma(U, V) = \bigg(\frac{\partial \sigma}{\partial U}\bigg)_{V} dU +
	            \bigg(\frac{\partial \sigma}{\partial V}\bigg)_{U} dV
\end{equation}
Setting the left hand side equal to zero, dividing through by $dV$, and then substituting in our previous expressions for pressure (\cref{eq:Pressure})
and temperature (\cref{eq:Temp}), we get the following relationship:

\begin{equation}
\frac{p}{\tau} = \bigg(\frac{\partial \sigma}{\partial V}\bigg)_{U}
\end{equation}

putting this together with the previous equation, we find that
$dU = \tau d\sigma - p dV$, the expression for the total energy of
the system.


\subsection{Summary}
\begin{itemize}
\item The probability of finding a system (in microstate $s$ with
	energy $\epsilon_s$, in thermal equilibrium with a reservoir 
	at temperature $\tau_R$) is proportional to the 
	\emph{Boltzmann factor} $P(s) \propto exp(-\epsilon_s/\tau_R)$.

\item To normalize $P(s)$ properly ($\sum_{s} P(s) = 1$), we divide
	the Boltzmann factor by the sum over all energy states.
	$P(s) = exp(-\epsilon_s/\tau_R)/Z$, where 
	$Z(\tau_R) \equiv \sum_{s} exp(-\epsilon_s/\tau_R)$. $Z$ is called the
	partition function.

\item For a compressible system, if we change the volume slowly and by
	a small amount, the entropy won't change (\textit{isentropic}). This
	is defined as \textit{pressure}: $p = -(\partial U/\partial V)_\sigma$

\item The picture of closed system with an accessible number of microstates
	and associated entropy is the \emph{microcanonical ensemble}. In this picture, the energy, volume, and number of the system is fixed.

\item The \emph{canonical ensemble} is the similar picture, but with 
	the system now in thermal equilibrium with a heat bath. Consequently,
	the temperature is now fixed, but the energy of the system is not.

\item Adiabatic vs. Isentropic vs. Isothermal: Isentropic and 
	Isothermal are clearly defined ($d\sigma = 0$ or $d\tau = 0$). But
	adiabatic has confusing and contradictory definitions in quantum
	mechanics and thermodynamics...
\end{itemize}




