\section{Entropy: April 9}

\subsection{Entropy}
\label{s:Entropy}
The number of microstates is a huge number! Its much easier to work with the
logarithm of such large numbers. The logarithm is also convenient since adding
systems together requires just adding their logarithms, rather than multiplying
the number of microstates.

So we define \textit{\textbf{entropy}} as:
\begin{equation}
\sigma \equiv log(g)
\end{equation}
This is a dimensionless (unitless) quantity (its just the logarithm 
of a large number...). \\

As we saw in the previous lecture, the combined system moves from its initial configuration
(where system 1 and 2 have the energies $U_1$ and $U_2$, respectively) into the one which
is \emph{overwhelmingly} likely. Recall that our conclusion from the discussion of thermal
equilibrium is that for macroscopic systems (e.g. with $N \gtrsim 10^{15}$...actually the
transition from micro to macro is a fuzzy concept, but this is an OK estimate for now), the
chances of the energy being even 1\,ppm different from the most probable value are astronomically unlikely (really? Yes - see the Shakespeare, monkeys, and typewriters
problem in this week's problem set).

\begin{equation}
\bigg(\frac{\partial \sigma_1}{\partial U_1}\bigg)_{N_1} = 
\bigg(\frac{\partial \sigma_2}{\partial U_2}\bigg)_{N_2}
\label{eq:Teq}
\end{equation}

This tendency of the system to always move into a configuration which maximizes
the number of accessible micro-states ($g$) is a just another way of stating the
2$^{\rm nd}$ Law of Thermodynamics: The entropy of a closed system will always 
increase until the system reaches equilibrium.

\epigraph{Turning and turning in the widening gyre \\
The falcon cannot hear the falconer; \\
Things fall apart; the centre cannot hold; \\
Mere anarchy is loosed upon the world,...}{\textit{William B. Yeats, 1919}}

\subsection{Temperature}
\label{s:Temperature}

Intuitively, we know that putting things in contact brings them to the same temperature
(cf. the "Brain Freeze" available at the Red Door Cafe). So we want this to be
implied by Eq.~\ref{eq:Teq}.

From Eq.~\ref{eq:Teq}, we could pick $\tau, 1/\tau, or -\tau,...$, but we want temperature
to correspond to our human definitions of it. Zero temperature should be very low energy
and temperature should rise as we put more kinetic energy into the particles, so we define
it like so:
\begin{equation}
\frac{1}{\tau} \equiv \bigg(\frac{\partial \sigma}{\partial U}\bigg)_{N}
\label{eq:Temp}
\end{equation}

\newpage
\subsection{The Laws of Thermodynamics}

\subsubsection{The 0$^{\rm th}$ Law: Thermometers}
\href{http://en.wikipedia.org/wiki/Zeroth_law_of_thermodynamics}{Wikipedia:Zeroth Law}

From our definitions of temperature and thermal equilibrium 
(cf. \cref{eq:Temp,eq:Teq}), 
we see that if $\tau_1 = \tau_3$ and $\tau_2 = \tau_3$, then 
$\tau_1 = \tau_2$. 
In this example, $\tau_3$ is the temperature of the thermometer we are 
using to establish the equivalence of the temperatures of our two example 
systems (1 and 2). Why is this seemingly trivial statement worthy
of being a so-called "Law of Thermodynamics"? 



\subsubsection{The 1$^{\rm st}$ Law: No Free Lunch}
\begin{figure}[h]
\centering
\includegraphics[width=0.5\columnwidth]{Figures/Carnot_heat_engine_2.pdf}
\caption{Schematic diagram of Carnot's Heat Engine \\
	\url{http://commons.wikimedia.org/wiki/File:Carnot_heat_engine_2.svg}}
\end{figure}
A concise statement of the 1$^{\rm st}$ Law is:
\begin{equation}
\Delta U = Q + W
\label{eq:FirstLaw}
\end{equation}
where $\Delta U$ is the total internal energy of our system, $W$ is the
mechanical work done \emph{to the system}\footnote{note the sign convention
here; the work is done to the system and not by the system}, and $Q$ is
the \textit{heat}. But what is heat? We all know what it is intuitively,
but it is important to define it such that it can be used consistently in
our studies of statistical mechanics. As defined in Ch.~8 of the textbook,
heat is the energy transfer between two systems which are in thermal contact.
It does not include work or any transfer of material. In the Carnot example
above, $W = Q_H - Q_C$. Systems where $W > Q_H - Q_C$ are called
perpetual motion machines of the first kind, and are known to be
impossible to conservation of energy.

\subsubsection{The 2$^{\rm nd}$ Law: Everything Runs Down}
As we saw above in Sec.~\ref{s:Entropy}, when a system begins in a
non-equilibrium state (such as the one where we first bring the two
sub-systems into contact), it always moves in the direction which
increases the entropy:\footnote{This is put to music in the song "Unsustainable", from the rock band Muse's album "The 2nd Law". Some Gaussian distributions and combinatorics are displayed for affect in their music video:
\href{https://www.youtube.com/watch?v=EF_xdvn52As}{YouTube:Unsustainable}} pieces of a broken wine glass "never" reassemble
into a whole glass. When we run the film backwards, we see this happen,
but it seems that there is a preferred to direction to the 
flow of time. This is often referred to as the 
Arrow of TIme~\footnote{\href{http://www.wired.com/2014/04/quantum-theory-flow-time/}{2004 Wired article} on how quantum correlations may be the underlying basis for the arrow of time}

For the heat engine example above, $\Delta \sigma = Q_C/\tau_C - Q_H/\tau_H$.
In order for $\Delta \sigma$ to be positive, we must have $\tau_H > \tau_C$,
since $Q_H \ge Q_C$.



\subsubsection{The 3$^{\rm rd}$ Law: Nernst Theorem}
The entropy of all systems approaches zero as the system goes towards
absolute zero temperature: $\sigma \rightarrow 0$, and $\partial \sigma /\partial \tau \rightarrow 0$ as $\tau \rightarrow 0$. \\

This is simply a consequence of the ground state multiplicity. There is only
one "lowest energy state", so in that state $g = 1$ and so 
$log(g) = 0$. \\

There are some unusual systems for which this is not quite true.
Some glassy systems or magnetic systems with geometric domains of different
order can asymptote to a state of small, non zero entropy as the temperature
goes to absolute zero.



\epigraph{The law that entropy always increases, holds, I think, the supreme position among the laws of Nature. If someone points out to you that your pet theory of the universe is in disagreement with Maxwell's equations --- then so much the worse for Maxwell's equations. If it is found to be contradicted by observation --- well, these experimentalists do bungle things sometimes. But if your theory is found to be against the second law of thermodynamics I can give you no hope; there is nothing for it but to collapse in deepest humiliation.}
{\textit{Sir Arthur S. Eddington, 1928}}

